than that of pristine InVO4 sample. The characterization results reveal that the introduction of OVs augments light consumption and impedes the recombination of photogenerated electrons-hole pairs. Furthermore, the effect of OVs by doping Mo on the nitrogen fixation performance is also verified by the density functional theory (DFT) theoretical calculation. This work provides a new platform for the development of promising catalysts in the photocatalytic nitrogen fixation field, and has certain theoretical and practical value. ", "authors": {"total": 12, "data": [{"display_name": "Juan Wang", "full_slug": null}, {"display_name": "Zihao Guo", "full_slug": null}, {"display_name": "Li Cheng", "full_slug": null}, {"display_name": "Yi Fan", "full_slug": null}, {"display_name": "Yulu Wang", "full_slug": null}, {"display_name": "Cheng Zhong", "full_slug": null}, {"display_name": "Hang Zhang", "full_slug": null}, {"display_name": "Zongzhao Sun", "full_slug": null}, {"display_name": "Shengjie Xia", "full_slug": null}, {"display_name": "Yufeng Jin", "full_slug": null}, {"display_name": "Lei Yang", "full_slug": null}, {"display_name": "Woon\u2010Ming Lau", "full_slug": null}]}, "affiliations": {"total": 0, "data": []}, "metrics": {"citations": {"total": null}}, "paper_url": "https://typeset.io/papers/experimental-and-theoretical-study-on-potentiated-485q8gb3j9?utm_source=chatgpt"}, {"id": 4017976772, "title": "Statistical Inference With Anchored Bayesian Mixture of Regressions Models: An Illustrative Study of Allometric Data", "is_archived": false, "full_slug": "statistical-inference-with-anchored-bayesian-mixture-of-2ordqfl5", "journal": {"display_name": "Statistica Sinica", "official_page": "http://www3.stat.sinica.edu.tw/statistica", "issn": "1017-0405", "alias": null, "id": 23408671, "slug": "statistica-sinica", "unique_id": "1rn94oko", "full_slug": "statistica-sinica-1rn94oko"}, "conference_series": null, "date": "2025-01-01T00:00:00Z", "is_oa": true, "publication_type": "Journal Article", "doi": "10.5705/ss.202021.0387", "abstract": ": We present an illustrative study in which we use a mixture of regressions model to improve on an ill-\ufb01tting simple linear regression model relating log brain mass to log body mass for 100 placental mammalian species. The slope of the model is of particular scienti\ufb01c interest because it corresponds to a constant that governs a hypothesized allometric power law relating brain mass to body mass. We model these data using an anchored Bayesian mixture of regressions model, which modi\ufb01es the standard Bayesian Gaussian mixture by pre-assigning small subsets of observations to given mixture components with probability one. These observations (called anchor points) break the relabeling invariance (or label-switching) typical of exchangeable models. In the article, we develop a strategy for selecting anchor points using tools from case in\ufb02uence diagnostics. We compare the performance of three anchoring methods on the allometric data and in simulated settings.", "metrics": {"citations": {"total": null}}, "paper_url": "https://typeset.io/papers/statistical-inference-with-anchored-bayesian-mixture-of-2ordqfl5?utm_source=chatgpt"}, {"id": 4037719739, "title": "A systematic study of DNN based speech enhancement in reverberant and reverberant-noisy environments", "is_archived": false, "full_slug": "a-systematic-study-of-dnn-based-speech-enhancement-in-2ye5iz8a3q", "journal": {"display_name": "Computer Speech & Language", "official_page": "https://www.journals.elsevier.com/computer-speech-and-language", "issn": "0885-2308", "alias": ["Computer speech and language"], "id": 91252481, "slug": "computer-speech-language", "unique_id": "2wykbdr5", "full_slug": "computer-speech-language-2wykbdr5"}, "conference_series": null, "date": "2025-01-01T00:00:00Z", "is_oa": null, "publication_type": "Journal Article", "doi": "10.1016/j.csl.2024.101677", "abstract": "Deep learning has led to dramatic performance improvements for the task of speech enhancement, where deep neural networks (DNNs) are trained to recover clean speech from noisy and reverberant mixtures. Most of the existing DNN-based algorithms operate in the frequency domain, as time-domain approaches are believed to be less effective for speech dereverberation. In this study, we employ two DNNs: ARN (attentive recurrent network) and DC-CRN (densely-connected convolutional recurrent network), and systematically investigate the effects of different components on enhancement performance, such as window sizes, loss functions, and feature representations. We conduct evaluation experiments in two main conditions: reverberant-only and reverberant-noisy. Our findings suggest that incorporating larger window sizes is helpful for dereverberation, and adding transform operations (either convolutional or linear) to encode and decode waveform features improves the sparsity of the learned representations, and boosts the performance of time-domain models. Experimental results demonstrate that ARN and DC-CRN with proposed techniques achieve superior performance compared with other strong enhancement baselines. ", "authors": {"total": 3, "data": [{"display_name": "Heming Wang", "full_slug": null}, {"display_name": "Ashutosh Pandey", "full_slug": null}, {"display_name": "DeLiang Wang", "full_slug": null}]}, "affiliations": {"total": 0, "data": []}, "metrics": {"citations": {"total": null}}, "paper_url":